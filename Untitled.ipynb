{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition using Distributed Computing\n",
    "\n",
    "## Technologies used:\n",
    "\n",
    "    - Apache PySpark\n",
    "    - Spark ML\n",
    "    - H2O\n",
    "    - AWS EMR\n",
    "    - AWS S3\n",
    "\n",
    "\n",
    "## Contributors\n",
    "\n",
    "- Shreejaya Bharathan\n",
    "- Ivette Sulca\n",
    "- Roja Immani\n",
    "- Aakanksha Nallabothula Surya\n",
    "- Sakshi Singla\n",
    "- Akansha Shrivastava\n",
    "\n",
    "## Goal\n",
    "Determine which device-meter combination is best at recognizing Human activities among the following available devices and sensors per device:\n",
    "    - Devices: Phone, watch\n",
    "    - Sensors: Accelerometer, Gyrometer\n",
    "    \n",
    "    \n",
    "## Dataset\n",
    "\n",
    "source : https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+\n",
    "\n",
    "Data (X,Y,Z coordinates) has been collected for 51 subjects for about 18 activities at a rate of 20Hz for 3 mins each:\n",
    "\n",
    "    • Non hand-oriented:walking, jogging, stairs, standing, kicking \n",
    "    • Hand-oriented (G): dribbling, playing catch, typing, writing, clapping, brushing teeth, folding clothes\n",
    "    • Hand-oriented (E): eating pasta, eating soup, eating sandwich, eating chips, drinking\n",
    "    \n",
    "2 devices & 2 sensor types :\n",
    "\n",
    "    device : phone & watch  \n",
    "    sensor : gyroscope & accelerometer \n",
    "    \n",
    "Number or observations: 15630426\n",
    "\n",
    "\n",
    "## Process\n",
    "\n",
    "1) Data merged into one dataframe and stored to S3 bucket with the following columns:\n",
    "user, device, sensor_type, activity, timestamp, x, y, z\n",
    "\n",
    "2) Features extracted for each user-device-meter-activity combination:\n",
    "mean(x), mean(y), mean(z), std(x), std(y), std(z), covariance(x,y), covariance(y,z), covariance(z,x), histogram(x,4), hostogram(y,4), histogram(z,4), range(x), range(y), range(z)\n",
    "\n",
    "3) Fit 10 models on the extracted features with different device-sensor combinations and compared accuracies\n",
    "\n",
    "![image info](./images/accuracies.png)\n",
    "\n",
    "\n",
    "4) Found XGBoost with all four sensors to be the best at classifying the activities, ran it on various AWS EMR cluster settings to compare runtimes\n",
    "\n",
    "![image info](./images/best_model_runtimes.png)\n",
    "\n",
    "\n",
    "## Conclusions:\n",
    "\n",
    "1) All four sensors together classify human activities best\n",
    "\n",
    "2) XGBoost model using H2O gives the model with best accuracy (70%)\n",
    "\n",
    "3) Hand-oriented sitting activities like eating pasta, soup, sandwich etc are the most difficult to correctly identify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
